{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from collections import Counter\n",
    "from torch.utils.data import random_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "seed = 10\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "category_index_manual = 8\n",
    "n_val_manual = 5000\n",
    "\n",
    "data_path_manual = '/cifar-10-batches-py'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Function for loading the Cifar10 dataset.\n",
    "\n",
    "The method will have to be run twice. The first time we load it as tensors and split the set between training, validation, and testing. As this is a binary classification problem where we only want to identify whether an image is a ship or not, we can set all labels that are not \"ship\" to false.\n",
    "\n",
    "After running the method for the first time we get create a normalizer from the std and mean of the images. The method is then ran for a second time with the normalizer as the preprocessor."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:16: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  train_labels = np.array(transformed_cifar10_train_val)\n",
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_labels = np.array(transformed_cifar10_train_val)\n",
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:17: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  train_labels = np.array(train_labels == category_index).astype(int)\n",
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:19: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  test_labels = np.array(transformed_cifar10_test)\n",
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_labels = np.array(transformed_cifar10_test)\n",
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:20: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  test_labels = np.array(test_labels == category_index).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train dataset:         45000\n",
      "Size of the validation dataset:    5000\n",
      "Size of the test dataset:          10000\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(n_val, category_index, data_path, preprocessor):\n",
    "    transformed_cifar10_train_val = datasets.CIFAR10(\n",
    "        data_path,\n",
    "        train=True,\n",
    "        download=False,\n",
    "        transform = transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "    transformed_cifar10_test = datasets.CIFAR10(\n",
    "        data_path,\n",
    "        train=False,\n",
    "        download=False,\n",
    "        transform = transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "    train_labels = np.array(transformed_cifar10_train_val)\n",
    "    train_labels = np.array(train_labels == category_index).astype(int)\n",
    "\n",
    "    test_labels = np.array(transformed_cifar10_test)\n",
    "    test_labels = np.array(test_labels == category_index).astype(int)\n",
    "\n",
    "    n_train = len(transformed_cifar10_train_val)-n_val\n",
    "\n",
    "    transformed_cifar10_train_split, transformed_cifar10_val_split = random_split(\n",
    "        transformed_cifar10_train_val,\n",
    "        [n_train, n_val],\n",
    "\n",
    "        generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "\n",
    "    print(\"Size of the train dataset:        \", len(transformed_cifar10_train_split))\n",
    "    print(\"Size of the validation dataset:   \", len(transformed_cifar10_val_split))\n",
    "    print(\"Size of the test dataset:         \", len(transformed_cifar10_test))\n",
    "\n",
    "    return transformed_cifar10_train_split, transformed_cifar10_val_split, transformed_cifar10_test, train_labels, test_labels\n",
    "\n",
    "cifar10_train, cifar10_val, cifar10_test, train_labels, test_labels = load_dataset(n_val_manual, category_index_manual, data_path_manual, preprocessor=transforms.ToTensor())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a normalizer for the dataset around the mean and standard deviation of the 3 dimensions (height, width channel (color)).\n",
    "\n",
    "Re-loading the dataset and applying the composition of transforms."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:16: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  train_labels = np.array(transformed_cifar10_train_val)\n",
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_labels = np.array(transformed_cifar10_train_val)\n",
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:17: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  train_labels = np.array(train_labels == category_index).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train dataset:         45000\n",
      "Size of the validation dataset:    5000\n",
      "Size of the test dataset:          10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:19: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  test_labels = np.array(transformed_cifar10_test)\n",
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_labels = np.array(transformed_cifar10_test)\n",
      "C:\\Users\\osten\\AppData\\Local\\Temp\\ipykernel_2880\\1344916318.py:20: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  test_labels = np.array(test_labels == category_index).astype(int)\n"
     ]
    }
   ],
   "source": [
    "imgs = torch.stack([img for img, _ in cifar10_train])\n",
    "\n",
    "normalizer = transforms.Normalize(mean = imgs.mean(dim=(0, 2, 3)), std = imgs.std(dim=(0, 2, 3)))\n",
    "\n",
    "cifar10_train, cifar10_val, cifar10_test, train_labels, test_labels = load_dataset(n_val_manual, category_index_manual, data_path_manual, preprocessor=transforms.Compose([transforms.ToTensor(),normalizer]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Choosing a pre-trained CNN model. We choose ResNet18, which is not trained on Cifar-10."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osten\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\osten\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\osten/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0.00/44.7M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e84ce1437a648a6842463b274e74179"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.optim' has no attribute 'adam'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_2880\\2576438796.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;31m# Legge til spørsmål om vi burde bruke SGD, Adam, RMSprop eller noe annet\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;31m# Legge til spørsmål om vi burde endre på learning raten, eller i alle fall forklare hvorfor vi bruker den vi bruker\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m \u001B[0moptimizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madam\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0mlr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.001\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torch.optim' has no attribute 'adam'"
     ]
    }
   ],
   "source": [
    "# Loading pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the last layer. We are doing binary classification, so i think we only need one node in the final layer.\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features,1)\n",
    "\n",
    "# \"Remember to use a suitable loss function like Binary Cross Entropy with Logits Loss (BCEWithLogitsLoss) and an optimizer like Adam or SGD for training.\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Legge til spørsmål om vi burde bruke SGD, Adam, RMSprop eller noe annet\n",
    "# Legge til spørsmål om vi burde endre på learning raten, eller i alle fall forklare hvorfor vi bruker den vi bruker\n",
    "optimizer = optim.adam(model.parameters(),  lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Counter([label for _, label in cifar10_train])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imgs = torch.stack([img for img, _ in tensor_cifar10_train_val])\n",
    "print(imgs.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a normalizer for the dataset around the mean and standard deviation of the 3 dimensions (height, width channel (color))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalizer = transforms.Normalize(mean = imgs.mean(dim=(0, 2, 3)), std = imgs.std(dim=(0, 2, 3)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading the dataset and applying the composition of transforms."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt at plotting the normalized images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = tensor_cifar10_train_val.data[1]\n",
    "print(img_t)\n",
    "print(\"halla\")\n",
    "print(img_t.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tensor_cifar10_train_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_t.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
