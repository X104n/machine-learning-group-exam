{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "301633e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#TO Encode, Scale and split data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#The Models we are going to use\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#To make a print_score function\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad63551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and preprocess it\n",
    "dataset =  pd.read_csv(\"agaricus-lepiota.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ef74403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.head()\n",
    "#dataset.info() #Shows that every row has non-null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b0594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wanted to see a heatmap of the correletaiom between the different values and collum.\n",
    "#This will show the  most indicative features in the dataset and the most domentating feutures. \n",
    "corr = dataset.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aa3c722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to drop some coloms because of the logical rules in the dataset.\n",
    "#This is features that are the most indicative, and we would therefore drop these before running the models. \n",
    "dataset = dataset.drop(columns='p.1') #Odor\n",
    "dataset = dataset.drop(columns='k.1') #Spore-print-color\n",
    "dataset = dataset.drop(columns='u') #Habitant\n",
    "dataset = dataset.drop(columns='s.3') #Population\n",
    "dataset = dataset.drop(columns='s.1')#Above\n",
    "dataset = dataset.drop(columns='s.2')#below\n",
    "dataset = dataset.drop(columns='p.3')#ring-type\n",
    "dataset = dataset.drop(columns='e.1')#stalk-root\n",
    "dataset = dataset.drop(columns='k')#gill-color\n",
    "dataset = dataset.drop(columns='t')#bruises?\n",
    "dataset = dataset.drop(columns='c')#gill-spacing\n",
    "dataset = dataset.drop(columns='n.1')#gill-size\n",
    "dataset = dataset.drop(columns='e')#stalk-shape\n",
    "dataset = dataset.drop(columns='n')#cap-color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d5f38394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Label Encoding, so that the cells contain corresponding number for the character, and replaces it. \n",
    "Encoder = LabelEncoder() \n",
    "for col in dataset.columns:\n",
    "    dataset[col] = Encoder.fit_transform(dataset[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "51d0054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'p'/class is the column that decides if the mushroom is edible or poisounus.  \n",
    "X=dataset.drop('p',axis=1) #Predictors 'p'=\"class\", This is what we are trying to predict.\n",
    "y=dataset['p'] #Response, the data we have to work with, is then the rest of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "92d0ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X = pd.DataFrame(scalar.fit_transform(X), columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b73bd105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f97acb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to use KNN, DecisionTreeclassifier and RandomForrestClassifier because "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "10a2b215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(oob_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(oob_score=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(oob_score=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "knn = KNN()\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "#DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=5, criterion=\"entropy\")\n",
    "dtc.fit(X_train,y_train)\n",
    "\n",
    "#RandomForrestClassifier\n",
    "rfc = RandomForestClassifier(oob_score=True)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "41f2a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to print a classification report for the different models.\n",
    "def print_score(classifier,X_train,y_train,X_test,y_test, name):\n",
    "    print(\"Training results for\", name, \":\\n\")\n",
    "    print('Classification Report:\\n{}\\n'.format(classification_report(y_train,classifier.predict(X_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c61f638d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for KNN :\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83      2945\n",
      "           1       0.87      0.72      0.79      2741\n",
      "\n",
      "    accuracy                           0.81      5686\n",
      "   macro avg       0.82      0.81      0.81      5686\n",
      "weighted avg       0.82      0.81      0.81      5686\n",
      "\n",
      "\n",
      "Training results for DTC :\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.52      0.67      2945\n",
      "           1       0.65      0.96      0.78      2741\n",
      "\n",
      "    accuracy                           0.73      5686\n",
      "   macro avg       0.79      0.74      0.72      5686\n",
      "weighted avg       0.80      0.73      0.72      5686\n",
      "\n",
      "\n",
      "Training results for RFC :\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83      2945\n",
      "           1       0.80      0.88      0.84      2741\n",
      "\n",
      "    accuracy                           0.83      5686\n",
      "   macro avg       0.84      0.84      0.83      5686\n",
      "weighted avg       0.84      0.83      0.83      5686\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(knn,X_train,y_train,X_test,y_test,\"KNN\")\n",
    "print_score(dtc,X_train,y_train,X_test,y_test,\"DTC\")\n",
    "print_score(rfc,X_train,y_train,X_test,y_test,\"RFC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b8923",
   "metadata": {},
   "source": [
    "c) Our best performing model is the RandomForrest classifier, as the average score is 83%. We would still not trust the model as there is still 20% that is wrong, and that can be dangerous. The dataset was originally sufficient because it would give a score of 100% for all three models. To really test the models we would need to decrease the numbers of colums and avoid the logical rules of the dataset. \n",
    "\n",
    "The decision tree classifier is a tree-like model that splits the data based on the most significant feature until a prediction can be made.\n",
    "We think the random forrest classifier perform best because it is an ensemble of decision trees, where each tree makes a prediction and the final prediction is made by combining the predictions of all trees. Therefore, the RFC is even more precise than the dtc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
