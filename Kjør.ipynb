{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1014,"status":"ok","timestamp":1682955428625,"user":{"displayName":"Østen Edvardsen","userId":"07919065933993283707"},"user_tz":-120},"id":"a_pW0g7-2xNf"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import numpy as np\n","import torch\n","\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","from collections import Counter\n","from torch.utils.data import random_split\n","\n","from torch.utils.data import DataLoader\n","\n","from torchvision import models\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from torch.utils.data import DataLoader\n","import torch.optim.lr_scheduler as lr_scheduler\n","import time"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1682955428626,"user":{"displayName":"Østen Edvardsen","userId":"07919065933993283707"},"user_tz":-120},"id":"Xt-MyJ9k2xNh"},"outputs":[],"source":["seed = 10\n","torch.manual_seed(seed)\n","\n","category_index = 8\n","n_val = 5000\n","\n","data_path = '/cifar-10-batches-py'\n","torch.set_default_dtype(torch.double)"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"BssbU-fM2xNj"},"source":["Function for loading the Cifar10 dataset.\n","\n","The method will have to be run twice.\n","After running the method for the first time we get create a normalizer from the std and mean of the images. The method is then ran for a second time with the normalizer as the preprocessor."]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"2--LqUA12xNm"},"source":["Loading the CIFAR-10 dataset as tensors."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1360,"status":"ok","timestamp":1682955429982,"user":{"displayName":"Østen Edvardsen","userId":"07919065933993283707"},"user_tz":-120},"id":"DSFTluQr2xNn","outputId":"3ee82ed8-52ad-4614-f731-43302937eb89"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n"]}],"source":["transformed_cifar10_train_val = datasets.CIFAR10(\n","    data_path,\n","    train=True,\n","    download=True,\n","    transform = transforms.ToTensor()\n",")"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"GHImKsY42xNq"},"source":["Stacking the set of images into a single tensor. We then create a normalizer for the dataset around the mean and standard deviation of the 3 dimensions (height, width channel (color))."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":16763,"status":"ok","timestamp":1682955446742,"user":{"displayName":"Østen Edvardsen","userId":"07919065933993283707"},"user_tz":-120},"id":"kXWLtJMM2xNs"},"outputs":[],"source":["imgs = torch.stack([img for img, _ in transformed_cifar10_train_val])\n","\n","normalizer = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean = imgs.mean(dim=(0, 2, 3)), std = imgs.std(dim=(0, 2, 3)))])"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"LJ49I_w_2xNt"},"source":["Loading the dataset as tensors for training+validation and testing. This time we apply the composition of transforms."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":940,"status":"ok","timestamp":1682955447673,"user":{"displayName":"Østen Edvardsen","userId":"07919065933993283707"},"user_tz":-120},"id":"KOfaMPHk2xNv"},"outputs":[],"source":["normalized_cifar10_train_val = datasets.CIFAR10(\n","    data_path,\n","    train=True,\n","    download=False,\n","    transform = normalizer\n",")\n","\n","\n","normalized_cifar10_test = datasets.CIFAR10(\n","    data_path,\n","    train=False,\n","    download=False,\n","    transform = normalizer\n",")"]},{"cell_type":"markdown","metadata":{"id":"DrIkLvSNl_nx"},"source":["Plotting image before and after transformation"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682955447673,"user":{"displayName":"Østen Edvardsen","userId":"07919065933993283707"},"user_tz":-120},"id":"U1McfzXTnTcy","outputId":"cd356d5d-e82c-4512-921f-6810a76f2889"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAgMAAAEJCAYAAAAJqCSsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2k0lEQVR4nO3deXxU5f098DOTTDKZ7CsJBEhYwiIgoKCgCKjIbhFxR0SsRdGqFQouVKzggmitVpHaupYiKKCiiFUBlbZBQDZl3/cASQhZJ5nJ3N8f/sjXIZwnkbIY7nm/Xv7hnMy9d7bLk5ucfByWZVkQERER23Ke7QMQERGRs0uLAREREZvTYkBERMTmtBgQERGxOS0GREREbE6LAREREZvTYkBERMTmtBgQERGxOS0GREREbK7OLAYcDket/vvqq6/O9qEGWbhwIS688EJERkbC4XDgww8/PNuHdEp89dVXtXq+33rrLTgcDqxYseLMHJhILRx7X7rdbuzatata3qNHD7Rp0+YsHNmpMXz4cGRkZATdlpGRgeHDh5/R49i5cyccDgfeeust49cdO5/Mnj37zByYVBN6tg+gtrKzs4P+f+LEiVi8eDEWLVoUdHvr1q3P5GEZWZaF66+/HllZWZg3bx4iIyPRokWLs31YIvL/lZeXY/z48fjHP/5xtg/ltPvggw8QExNztg9DfqHqzGLg4osvDvr/5ORkOJ3Oarcfr7S0FB6P53QeGrV//37k5+fjmmuuwRVXXHFKtllWVga32w2Hw3FKtidiZ3369MGMGTMwZswYnH/++adtP2VlZYiIiDht26+NDh06nNX9yy9bnfkxQW0cu7T3zTffoGvXrvB4PBgxYgQAYNasWbjqqquQlpaGiIgItGrVCg899BBKSkqCtjF8+HBERUVh69at6NevH6KiotCwYUOMHj0a5eXlQV/76quv4vzzz0dUVBSio6PRsmVLPPLIIwCAxx9/HOnp6QCAcePGweFwBF22+/e//40rrrgC0dHR8Hg86Nq1K+bPnx+0/WOXMj///HOMGDECycnJ8Hg8KC8vr3qs2dnZ6Nq1KyIiIpCRkYE333wTADB//nx07NgRHo8Hbdu2xWeffVbt+dqyZQtuvvlmpKSkIDw8HK1atcIrr7xS7es2btyIPn36wOPxICkpCXfddReKiop+5qtT/TneuHEjevfujcjISKSlpeGZZ54BACxduhSXXnopIiMjkZWVhbfffjvo/ocPH8aoUaPQunVrREVFISUlBZdffjmWLFlSbV979+7FkCFDEB0djbi4ONxyyy1Yvnz5CS9drlixAldffTUSEhLgdrvRoUMHvPfeeyf9OOWXb+zYsUhMTMS4ceNq/Fqv14uHH34YmZmZCAsLQ4MGDXDPPfegoKAg6OsyMjIwYMAAzJ07Fx06dIDb7cYf//jHqkvhM2bMwLhx45CWloaoqCgMHDgQBw8eRFFREX7zm98gKSkJSUlJuP3221FcXBy07VdeeQWXXXYZUlJSEBkZibZt2+LZZ5+Fz+er8fiP/zFBjx496I9bf/rZyMnJwciRI5Geno6wsDBkZmbij3/8I/x+f9D29+/fj+uvvx7R0dGIjY3FDTfcgJycnBqPi3n88cfhcDiwdu1aXHfddYiNjUVCQgIefPBB+P1+bNq0CX369EF0dDQyMjLw7LPPBt3f6/Vi9OjRaN++fdV9u3Tpgo8++qjavgoKCnDHHXcgISEBUVFR6N+/P7Zv3w6Hw4HHH3886Gtre96sa+rMlYHaOnDgAIYOHYqxY8fiqaeegtP543pny5Yt6NevHx544AFERkZi48aNmDx5MpYtW1btRw0+nw9XX3017rjjDowePRrffPMNJk6ciNjYWDz22GMAgJkzZ2LUqFH47W9/i+eeew5OpxNbt27F+vXrAQC//vWvcf7552Pw4MH47W9/i5tvvhnh4eEAgK+//hq9evVCu3bt8PrrryM8PBxTp07FwIED8e677+KGG24IOp4RI0agf//++Mc//oGSkhK4XC4AP35Ib7/9dowdOxbp6en4y1/+ghEjRmDPnj2YPXs2HnnkEcTGxuKJJ57AoEGDsH37dtSvXx8AsH79enTt2hWNGjXC888/j9TUVPzrX//Cfffdh9zcXEyYMAEAcPDgQXTv3h0ulwtTp05FvXr18M9//hP33nvv//Q6+Xw+DB48GHfddRd+//vfY8aMGXj44YdRWFiIOXPmYNy4cVWPafjw4WjTpg0uuOACAEB+fj4AYMKECUhNTUVxcTE++OAD9OjRAwsXLkSPHj0AACUlJejZsyfy8/MxefJkNGvWDJ999lm15xcAFi9ejD59+uCiiy7CtGnTEBsbi5kzZ+KGG25AaWnpGf9Zq5wZ0dHRGD9+PO6//34sWrQIl19++Qm/zrIsDBo0CAsXLsTDDz+Mbt26Ye3atZgwYQKys7ORnZ1d9fkGgJUrV2LDhg0YP348MjMzERkZWfWNxyOPPIKePXvirbfews6dOzFmzBjcdNNNCA0Nxfnnn493330Xq1atwiOPPILo6Gi89NJLVdvdtm0bbr755qoFyZo1a/Dkk09i48aNeOONN37WY586dSoKCwuDbvvDH/6AxYsXV/04MycnB507d4bT6cRjjz2Gpk2bIjs7G5MmTcLOnTurvvkoKyvDlVdeif379+Ppp59GVlYW5s+ff8LP2s91/fXXY+jQoRg5ciS++OKLqsXPl19+iVGjRmHMmDFVC6xmzZph8ODBAH78EVB+fj7GjBmDBg0aoKKiAl9++SUGDx6MN998E8OGDQMABAIBDBw4ECtWrMDjjz+Ojh07Ijs7G3369Kl2LLU9b9ZJVh112223WZGRkUG3de/e3QJgLVy40HjfQCBg+Xw+6+uvv7YAWGvWrAnaLgDrvffeC7pPv379rBYtWlT9/7333mvFxcUZ97Njxw4LgDVlypSg2y+++GIrJSXFKioqqrrN7/dbbdq0sdLT061AIGBZlmW9+eabFgBr2LBh1bZ97LGuWLGi6ra8vDwrJCTEioiIsPbt21d1++rVqy0A1ksvvVR1W+/eva309HTr6NGjQdu99957LbfbbeXn51uWZVnjxo2zHA6HtXr16qCv69WrlwXAWrx4sfE5OPYYli9fXnXbsed4zpw5Vbf5fD4rOTnZAmCtXLmy2mN68MEH6T78fr/l8/msK664wrrmmmuqbn/llVcsANaCBQuCvn7kyJEWAOvNN9+suq1ly5ZWhw4dLJ/PF/S1AwYMsNLS0qzKykrj45S65afvy/LycqtJkybWhRdeWPXZ6969u3XeeedVff1nn31mAbCeffbZoO3MmjXLAmC99tprVbc1btzYCgkJsTZt2hT0tYsXL7YAWAMHDgy6/YEHHrAAWPfdd1/Q7YMGDbISEhLoY6isrLR8Pp/1zjvvWCEhIVWfWcv68TPWuHHjoK9v3Lixddttt9HtTZkypdpjGTlypBUVFWXt2rUr6Gufe+45C4C1bt06y7Is69VXX7UAWB999FHQ1915553VPmsncuy5ef/996tumzBhggXAev7554O+tn379hYAa+7cuVW3HTt/DB48mO7j2HnijjvusDp06FB1+/z58y0A1quvvhr09U8//bQFwJowYULVbbU9b9ZF59SPCQAgPj7+hKv77du34+abb0ZqaipCQkLgcrnQvXt3AMCGDRuCvtbhcGDgwIFBt7Vr1y7ot447d+6MgoIC3HTTTfjoo4+Qm5tbq+MrKSnBt99+iyFDhiAqKqrq9pCQENx6663Yu3cvNm3aFHSfa6+99oTbSktLq/puGQASEhKQkpKC9u3bV10BAIBWrVoBQNXxe71eLFy4ENdccw08Hg/8fn/Vf/369YPX68XSpUsB/Pgd83nnnVft56k333xzrR4v43A40K9fv6r/Dw0NRbNmzZCWlhb0s81jj+n43/ieNm0aOnbsCLfbjdDQULhcLixcuDDotfz6668RHR1dbYV/0003Bf3/1q1bsXHjRtxyyy0AUO35OHDgQLXXRM4dYWFhmDRpElasWEF/LHTs6uHxV4iuu+46REZGYuHChUG3t2vXDllZWSfc1oABA4L+/9jns3///tVuz8/PD/pRwapVq3D11VcjMTGx6jw2bNgwVFZWYvPmzTU/WOLdd9/F2LFjMX78eNx5551Vt3/yySfo2bMn6tevH/S56Nu3L4AfP2PAj+eJ6OhoXH311UHb/V/PE8CJny+Hw1F1DMD/nT+OP0+8//77uOSSSxAVFVV1nnj99dernSeAH69A/NTx54mfc96si865xUBaWlq124qLi9GtWzd8++23mDRpEr766issX74cc+fOBfDjJa6f8ng8cLvdQbeFh4fD6/VW/f+tt96KN954A7t27cK1116LlJQUXHTRRfjiiy+Mx3fkyBFYlnXC4zz2D3heXl6Njwn48R/K44WFhVW7PSwsDACqjj8vLw9+vx9/+ctf4HK5gv479g/0scVNXl4eUlNTq+3nRLf9HCd6jk907Mdu/+lz/6c//Ql33303LrroIsyZMwdLly7F8uXL0adPn6DXMi8vD/Xq1au2veNvO3jwIABgzJgx1Z6PUaNGAUCtF3tSN914443o2LEjHn300RP+/D0vLw+hoaFITk4Out3hcCA1NbXWn1mg+uf22Oezps/t7t270a1bN+zbtw8vvvgilixZguXLl1f9vPr481htLV68GMOHD8ewYcMwceLEoOzgwYP4+OOPq30uzjvvPADB54kTfdb+1/MEcOLnhZ0/fnqemDt3Lq6//no0aNAA06dPR3Z2NpYvX44RI0YEfd2x1/b4/Rz/eH7OebMuOud+Z+BEv2W/aNEi7N+/H1999VXV1QAA1X7x5+e6/fbbcfvtt6OkpATffPMNJkyYgAEDBmDz5s1o3LjxCe8THx8Pp9OJAwcOVMv2798PAEhKSgq6/VQ3B+Lj46uuRNxzzz0n/JrMzEwAQGJi4gl/Ceh/+cWg/9X06dPRo0cPvPrqq0G3H/9LjYmJiVi2bFm1+x9/7Mee74cffrjq543HUyX03OZwODB58mT06tULr732WrU8MTERfr8fhw8fDloQWJaFnJwcdOrUqdr2TrUPP/wQJSUlmDt3btD5ZfXq1Se9zbVr12LQoEHo3r07/va3v1XLk5KS0K5dOzz55JMnvP+xb2Bq+1k7k6ZPn47MzEzMmjUr6PU4/hfBj722+fn5QQuC44/955w366Jz7srAiRx7I/z0F3wA4K9//esp2X5kZCT69u2LRx99FBUVFVi3bp3xay+66CLMnTs3aCUfCAQwffp0pKen08uLp4rH40HPnj2xatUqtGvXDhdeeGG1/xITEwEAPXv2xLp167BmzZqgbcyYMeO0HqOJw+Go9lquXbu22t+i6N69O4qKirBgwYKg22fOnBn0/y1atEDz5s2xZs2aEz4XF154IaKjo0/Pg5FfjCuvvBK9evXCE088Ue23+I9Vg6dPnx50+5w5c1BSUnLKqsMmJzqPWZZ1wn/Ea2P37t3o27cvmjRpgjlz5lT9YvJPDRgwAD/88AOaNm16ws/FscVAz549UVRUhHnz5gXd/2yfJ8LCwoIWAjk5OdXaBMe+QZw1a1bQ7cefJ37OebMuOueuDJxI165dER8fj7vuugsTJkyAy+XCP//5z2r/wP0cd955JyIiInDJJZcgLS0NOTk5ePrppxEbG1vtu4TjPf300+jVqxd69uyJMWPGICwsDFOnTsUPP/yAd99994z8DYEXX3wRl156Kbp164a7774bGRkZKCoqwtatW/Hxxx9X/Yz0gQcewBtvvIH+/ftj0qRJVW2CjRs3nvZjZAYMGICJEydiwoQJ6N69OzZt2oQnnngCmZmZQXWn2267DS+88AKGDh2KSZMmoVmzZliwYAH+9a9/AUBV0wT4cWHYt29f9O7dG8OHD0eDBg2Qn5+PDRs2YOXKlXj//ffP+OOUM2/y5Mm44IILcOjQoapL4QDQq1cv9O7dG+PGjUNhYSEuueSSqjZBhw4dcOutt572Y+vVqxfCwsJw0003YezYsfB6vXj11Vdx5MiRk9pe3759UVBQgJdffrnaNzBNmzZFcnIynnjiCXzxxRfo2rUr7rvvPrRo0QJerxc7d+7Ep59+imnTpiE9PR3Dhg3DCy+8gGHDhuHJJ59E8+bN8emnn1Z91s6GY/XOUaNGYciQIdizZw8mTpyItLQ0bNmyperr+vTpg0suuQSjR49GYWEhLrjgAmRnZ+Odd94BEHyeqO15sy6yxZWBxMREzJ8/Hx6PB0OHDsWIESMQFRVVbSX4c3Tr1g0//PAD7r//fvTq1Qu/+93vkJWVhSVLllT7ueLxunfvjkWLFiEyMhLDhw/HjTfeiKNHj2LevHmnpIpTG61bt8bKlSvRpk0bjB8/HldddRXuuOMOzJ49O+i7nNTUVHz99ddo3bo17r77bgwdOhRutxsvv/zyGTnOE3n00UcxevRovP766+jfvz/+/ve/Y9q0abj00kuDvi4yMhKLFi1Cjx49MHbsWFx77bXYvXs3pk6dCgCIi4ur+tqePXti2bJliIuLwwMPPIArr7wSd999N7788ktceeWVZ/LhyVnUoUOHar84BqDqT4k/+OCDePPNN9GvXz8899xzuPXWW7Fo0aJqV6pOh5YtW2LOnDk4cuRIVWW5ffv2QdXDn2P9+vUoLS3F4MGD0aVLl6D/jv3Nk7S0NKxYsQJXXXUVpkyZgj59+lT9vlT79u0RHx8P4MfvmhctWoQrr7wSDz30EIYMGYK9e/dW++76TLr99tvxzDPPYMGCBejXrx8mT56Mhx56qNovNTqdTnz88ce48cYb8cwzz+BXv/oVlixZUnUV6KfnidqeN+sih2VZ1tk+CJEz6amnnsL48eOxe/fuqj8MJSLyUzNmzMAtt9yC//znP+jatevZPpzTzhY/JhD7OnYFo2XLlvD5fFi0aBFeeuklDB06VAsBEQHwY7Vy3759aNu2LZxOJ5YuXYopU6bgsssus8VCANBiQM5xHo8HL7zwAnbu3Iny8nI0atQI48aNw/jx48/2oYnIL0R0dDRmzpyJSZMmoaSkBGlpaRg+fDgmTZp0tg/tjNGPCURERGzOFr9AKCIiIpwWAyIiIjanxYCIiIjNaTEgIiJic7VuE/xt3pc027vxO5od3rGBZpWVfPf1GrWkWaOmrWgWn9qIZu4Ivr/N6/5LMwDYtXUtzXxFxTQLMTzGmPhYmoW6PTTrfMllNGuWxZ8379F8mq37YRXNAoEKmlX4vDRbv+57mhUW8IEe5RXlNPNVhNAsP6+UZgBQXMqP1V/J95mcXH140jHxCVE0q7SKaOavPgunireM/07vh3PP3l90O1m/386zPw29jmaB7Nknt8PM4TR66IW/06zXr/h7K8Owu988847xcBY+fJsxPzmRNAlL5XM0thzg52p+5jT753z+nvR6D9IsJ3cXzcbf9dhJHo0wNXUFdGVARETE5rQYEBERsTktBkRERGxOiwERERGb02JARETE5mrdJig8wn8TPTGO/7a1lVyPZ6ExNEtr1IRmlQH+q9jOAP+N8kCpn2beI3k0AwCrjP8meoOkFJo1atiMZg2bNaZZ/QZ8iE5KCn9OXS4+StUfxxsKDdNT+f38vE3g9ZbRrOAIb1nk5vL3U2iYm2Zw8N/4jk80j5F1R/JjPVrIZ8KHu/nHJGDx95QrlB9P4dECmlWUn1t/ITz7C94qGXh5L5p9tOoLvtG4zjS649EnaFbs5Z9zN/jnmH/6gZ2fLzCkZo3j+Gf54XHP0mzkQ8NOep+n2i39e5/ybS7+nLe3Fs49yZaJGOnKgIiIiM1pMSAiImJzWgyIiIjYnBYDIiIiNqfFgIiIiM1pMSAiImJzta4WwsfrfBXlPCst5bW0jKwGNCsuKeH7MwzHSUgyDP9x8bVP8+ZZNAOArhdfSLMG9XgNMDY2mWa+0Eqaedy8lhZqaJ45/LzqVlbCq37lhtfXE8ErifFxvI7VtElrmm3YsIlmcPBjKS/n1dHYmHi+TQCuMJ4dLeQDVSzw93AgwF+MI0f4e7islA9GqmGeSN1zmNf5cvYYKr3eozS64Y6RNFv9/Xq+v8N8OE6fwb+hWZyLRnhl2os8BNA7611jLtX9acrbNDtf1cLTQlcGREREbE6LAREREZvTYkBERMTmtBgQERGxOS0GREREbE6LAREREZurdbXQb5hO5/Dzilx4WATNjubm0iwxldf1Gp3HJwGmNKxPM5epW+bndTYA8Pl5nXHjAV6PKt1+mG/TyStrm75fQ7NOrXhl77LOnWhmGTprhYW8xrV7136ahbn4hMGwMD6VMimZ10p379nCt+nmNcfiMl7lA4DCQv5+C3U5aBYTw/dZVsarjpW85Qm/P0Cz8HDD+7QOKtixnWahBbzuCvD3yL/nfkKzgSPuodnDf+YT9hoZjsSkdRav19ZksyHbYDgl5Rqqjr/u/wDN1s38M81aRxsO5gxLTeOfOcBUAzc9o2KiKwMiIiI2p8WAiIiIzWkxICIiYnNaDIiIiNicFgMiIiI2p8WAiIiIzdW6WlheymtbURG8XhaTwKf2dTy/Pc0aNmlOsyLDZL5N2/fQrLCU18CKCwpoBgB5Bbw+eCDnCM1iDFML4eST6z6ZNYdmruv5Gq57l0v5/Vy8q5SayiuZsHglr+BIEc1WrlpLs1AXn8oYGc0rif5KXo+sKC6gGQCEGJa+yckJNKus5BXQvHz+3DjB61GhofyjFxfHJ2/WRXs28CmCHZrzQt95PQfRbNmil2lmKqWZvG7IsvlpBasXfW/c7neLPuPhO4t51mUQz9z7eLaYT1Hs1p+fq/O+eYZv8wzrfNGjPEzilVPkqlp4snRlQERExOa0GBAREbE5LQZERERsTosBERERm9NiQERExOa0GBAREbG5WlcLw8P5mCxfCB93VRYRRbMdhXwS4up/L6NZfh6fdLZv/0GauUL4ZDqXk0+RA4ByP6+Xeb08S0vmT/GhnF00izFMrisqKKTZ5h07+LGkJdHM5eLHmdYwlWb1DdnuHN7H2vQ9z1LSeB1z525e5YPP/BoGKnheGconb7rDeA0yPJR/Lsq8fJsxMbw+GRrK91cXNWyYSLPcqI4029K8Hc0e5acHLFnF31vfzeN1V3w6k2fGUyWfaPojfk4yZmmGiuncyTXs88TylxieuF+QP748nGYjevPqZKB5Y77RLfx8K7oyICIiYntaDIiIiNicFgMiIiI2p8WAiIiIzWkxICIiYnNaDIiIiNhcrauFHk89mh0q4FMEt+7hNZ/1636gmdNQdass59P3yor4dMUQQ32wrJzX9QCgoIjnRSW86rhz7waaRUbwSmaLpi34wRhqjv9Z8hXNGmdm0iyrRRbNEhN5xSnczV+n2BhekXP6j9KspJyvUctK+aTHsgI+QREAKit5BcwdwSuCxYV8uzGGCYvh7hCaVVTw93CpYbpmXdSy1Y00m7OogN9xyUs0+vNrfJuAaeojnz5qzs6CuabHeLJ4lXHALRNp9tgzf6BZ54b/0wGdULcufDKh28vP8aVbeCZmujIgIiJic1oMiIiI2JwWAyIiIjanxYCIiIjNaTEgIiJic1oMiIiI2Fytq4VxCXzi3dY9m2l2YCefoudx8ZrY0ZIjNCsuPEQzR4DXBwuKeAWwoMw8eSzUMLUxqV4KzSKiec2pQcb5NGtoqKXtWJNNsxAHrx36KvkUvcO5vFbVtm0rmjVr3oRmDQ3TB6Mu7kCztRt306zc6+aZq4apheA1wIDF67E5OftpFhbO65Ox8fx9AfAKVFkZn+ZZF/Xsxyutcya/ZrjnWye5R9OUwHOE+xGeZfJJsdjA7zd/Bp8GmFvM36/devak2ZQHevNjMWji8tCsZNvzNBsy9E80m5O976SOxS50ZUBERMTmtBgQERGxOS0GREREbE6LAREREZvTYkBERMTmtBgQERGxuVpXC7dtW0azjdu20mz/gW00qzRMGIyOjaRZi+YZNGvTqg3NDhzmla1dh83TrpJT+dTGxk15dSo6kdfLDh7h+7RyeSVz9y5evTtcwCuCrVrTCL2yeH2wpJg/bwHeVoRVwWuO65byemTzFu1pVq9BHM2WLvuGHwyAnIN88qTPx6uF3jL+OI4c4RMNI6LiaBaweA2ypPTcmrz24AO38tA7/cwdSA1img+hWeGW7YZ7rq9hy4bpg6Meo9EFv+Lnle8+N+xu7pQajofh545v5/2dZq/9/Rmamcq+J/ud6PCmo2k2ddo9NLv1/m40G3Tj6ZgQWbfoyoCIiIjNaTEgIiJic1oMiIiI2JwWAyIiIjanxYCIiIjNaTEgIiJic1oMiIiI2Fyt/87A0m++4Bup14JmTVu1pVlEBW+htmrdnGYtstJpVunlo38tJ+/LlyCXZgAQ6uKjc0NC4mjm8/MRtyVF+TSLreC9d3+lRbPdh/joZ3cUH+EZGxNPsyZNM2hmGdaTZQWlNNv47Wq+zTL+vmjTuw/N2rbj45QBoGwF/zsD27bupJnHw0fCxsYlGvbI/whDYSF/ncrL+fNWF1Vkn+G/JZDKu/t//jvvoRfv5K/zU3/lfy+l9PtPajigRjTxRPO/JZDL3yLAMn7uwIGCGo7nZPC/QdCOTyo/Ld42ZP67XqHZ9FL+dyQmPc3/BgEAjH94SU2HVefpyoCIiIjNaTEgIiJic1oMiIiI2JwWAyIiIjanxYCIiIjNaTEgIiJic7WuFh7aw6t3Hc7vT7PwcN47SeAtQKTVj6FZfgEfG7tnK6/cVAR4zc/pMMziBRASyutulVY5v6OfP8WV5bzqaFXy/UXFJtEsr5iPv3WG8bHQAYvXFQFDZphRGuXmr2FG/YY0c4fw/TlRTLO2bXhNCwDi4uJoNq+Mz4TNOcA7Xg1S6tOs0uGlmcvF3xeFhbwCee7h42iROohn0Ty6ZVQnmi1YvIpm/3qe16eBBoaMvyd/xM8PpbxBjMMFhk3uNYxU9hrOR+eA7obMfAZYS5NHH+J1VADoefliml1y0VPG+9YVujIgIiJic1oMiIiI2JwWAyIiIjanxYCIiIjNaTEgIiJic1oMiIiI2Fytq4WeqASauQzNs4KCQzQLT4ijWamfd9a8vLGFiHjeOQoPOPgdveZqoWV4prw+PmXOHcHv6HRU0Czg5PeLSuR1tjCLVytDIvhkQiuM9zwDDv74HJW8rugM4Y/BFRlGs4gonvnLea00b99BmgFAYiSvuf6qX2+arVizk2bFZfw19JYfpll5Ga+VxkXH0cxWcmbzLIJPmdtYwKt1O3YY9te8I8/KDCeAvTVUC+MM2eEtNCptzie3ItTwXg+N5ZmhymhW72TveMrxYjXQLM4Q7uG10vzimcZ9dm17Dc2+XchriRddYaodnvSLcVroyoCIiIjNaTEgIiJic1oMiIiI2JwWAyIiIjanxYCIiIjNaTEgIiJic7WuFqY14vOgHE6+pvB6+QS2g4V892FxvEDi8/PqmcPlollZMa8A+Szzuig0lE889IfwzBPDJ/elJBbQzMrn1bMKH6+kOAL8cURERNDMaZggGbD4/ioreSXT6eIbtUL4cRaX8PqgI8Arp+GG9yEAFB7mdawID6/OXtalHc02bdtFsx/W59CsuJBPlwxzuWl27uGfHdOUOezg9bnv9gzg9ztiqMglJfJsleFYUMPrFW+YeBjFsxZd+N02Xd2Ih59u49kGHpk1Odk7nnKmQt7qAp7dZuikJ7jNr+Hm93j1sFmrXjQ7uv9Dmo14YDLN5ry3xHg8p4OuDIiIiNicFgMiIiI2p8WAiIiIzWkxICIiYnNaDIiIiNicFgMiIiI2V+tqoeXgNTGfoepWWsRrYuGGqltRIZ++V+HlU8lKC/n+XIahhdGRpooTkBzPq2cxCXxyX3Icf4yVhuliZeH8Oc1vzKcWllceoBkM0xUr/YYJioZpj5VOXvVzGKqFcQl8gmKg0nCchvdabCx/rgEgzMHHaxYUFdDM8vFKavtWqTSLi+bvqU8++Zxmhw/m0uzcc9SQrTRkhqpb9pc827GPZ17T/kwM1UEAnl68etaln4dm1/FGK4rvb0uzren8OZ32O0NfEdmGbDNN+Bng9Hy32dM0QdbQOwzk8ufF2c1cncwK5RXq3cu/oZn/MK+kzp45lGavdOLvqXt/b56weLJ0ZUBERMTmtBgQERGxOS0GREREbE6LAREREZvTYkBERMTmtBgQERGxuVpXC2GonoUGeBZrGAbVMJZX1lo2iaNZlJtXyEIcfH1TUlhAM2+pqeIERET6aNaiOa8dNmycTjOnqzHNigsK+DbT0vix7DhEs5gE/mIkxPPpiqGhfEpkgLf1YBkmIbojeaXKb+gHOQ37c9UwtdALXklNTIqiWXEprzqWFPDJhA2Sk2k2aOBVNPtwvqEad87hkySNUvmp6/Ep3WjWPpO/z6MNZ8Pvs3fQbOeG//I7AmjWNo9m9/Tn02CNGhqyBy6l0e9H8mN98OFVNOvSj5+rzvR3lBm8VYkC/jLBaRp3WOOkUF5JbTSYd0ADG3gl89Di6TS754ZBNIszvE+H/u7ka4e6MiAiImJzWgyIiIjYnBYDIiIiNqfFgIiIiM1pMSAiImJzWgyIiIjYXK2rhd27XECzJq3Pp9n+fbyS0aA+r+RlNW9Ks9TkFJqFWLyuWGSYTFdumOgHAA4n325UJJ9aGBXFKyshYbwi6TLUNctKDtOsYxteAcrIyqCZL8Crk5ZhzegP8L6OFcKfsxAXf+v5vLw/GDBMLXSGmte2DrdhbKXhvuU+/tyEhrhoVllRQLNkQ5Xx0m6daFYXXXv1EzR7dvYfaPbqi7zq9tt7OtCskXl45Um5PMtUATzJeuBZsOX772n24Z/5c/pLEs0bu8g1VAsDhwto5kQN1cJMwz+Vhlri3lxeK42LSqRZ6YElNLvuWl5l/CCbn/9roisDIiIiNqfFgIiIiM1pMSAiImJzWgyIiIjYnBYDIiIiNqfFgIiIiM3Vulp4QbuWNDuvA68WlrXhFcHIWD5BLGA4FsvBK2JOQ9UrITKVb7OGZZEpDgT40foNVTgYKmvl5WU0a9qsEc0iwnjNsayET2a0nIa3goNnlsNQA7R4Vml4DQOGUYgVZfx5qQzwxw4AzlDD+8bwChfl8drprh17aHbJpbyqVeoropnHVIGsg2Z/xOuDJlPG1I2qW13Su7Nh5F8dURTKz0dew8TTnC3baVYfrc07NVShYaglLv+ITy2cONVLs9WbhtCs9PBKmrXKNIyKrYGuDIiIiNicFgMiIiI2p8WAiIiIzWkxICIiYnNaDIiIiNicFgMiIiI2V+tqYYRpMp87nGaRHsMuQnkNwtAug8NULTRV1ixeAQz4TGVGc03O4TRM9TOUJA2DEGE5+Daj4vi0R38l319lwFA7CfCDsVBJM6fpQVTyrDKUV0AtGF58P5/m6Ajw4wSAcMPjd1Xy5zvSy+9nHeRVx8PbD9IsvUU6zXKdxTQTsbviOD7tzw/+mUOBIUOJeac+Q225mP/713Ynv58fvFq47Pezadb5rZE0a+nmUylroisDIiIiNqfFgIiIiM1pMSAiImJzWgyIiIjYnBYDIiIiNqfFgIiIiM3VuloYHcvrbJZhUmBpOa+CWeXlNCs33K+kmNdAKnz8fuXlfEqg32+uFvoMEwZ9hn2WlvKJd6UlfHKd3zAJMTohlmexcTSLi06imTssjGaVAf744OBTwpzgWXQ0n/SVd4jvz1vGa3eBQDzNAMAB/hgDlfy9GBPNq0ONG9WjWVkpf59aAf7cxEabpy+KPRQaGrYbvz9EsyNe/l7u1LkhzfgZ/pelU6fGNPt4Bq8P7tzCt1nfZ6odAgD/nKN4H42yOjWg2R8+zaPZlg18d529fPpst041TF800JUBERERm9NiQERExOa0GBAREbE5LQZERERsTosBERERm9NiQERExOZqXS38cN4CmlW6ltDsyBFe2Sg+mkszp6FWY6odHjzI91dpGIWYkJzCdwggPolPygoP4U9jSX4BzTYb+iOFxbxC1zCTV2tCXLzmGRPNH0NmZiOapTdM5fdrwqszCeF8amG0mx9nIDaGZgjhEwR9lbyuBwAhoXztG2I41noZhkpmDK8d+iw+RTGEtxyRkGB4/HXQxZ3H0Kw4uR3N1n0+k2/Uz89HvzxZhizOkC07xcdxejTtMppmvxt3C83u+VWHk9pfViY/j/XqZrhjlCEr5nU9AEAcr0Ij3fDP6OMDaHRDV37uhM8wuZSfjtGoXyce1kBXBkRERGxOiwERERGb02JARETE5rQYEBERsTktBkRERGxOiwERERGbc1iWZSjx/Z/efW6gWVx6C5pZlbwiseq/i2nWOD2dZkmJvFqybds2mvkDvOqV1c487SkxjU+tOrKP1xmv6NyFb9TQnywt9/K7uXiVZcfuXTTbvIU/N7l5vOYZF8s7OdcOuYZml5zHK1UFW3gdNTzAJ0RWGKqFIfG8HggAcPDn22lYF4e7eK2o0senSzqdfJuBEF6P9cNDswsuv5dmv1QOh+l1MX3u1p/qQzlLeBUY4J/Xh4a9ze/m5jXaDXv5Nt1JfOLprHee5ftDTVP9fr6HXubV0afv4f/eYA4/58DLJwEiytAtvIqfVwAAofzfDoDXi+EyvPY+fo6H4Zxjfi1MNdY/GjJdGRAREbE9LQZERERsTosBERERm9NiQERExOa0GBAREbE5LQZERERsrtZTC6+7aRjNwlOa06y0KIdmW75fQ7O01IY0M1W2Itx84ltFoIxmWW34YwCA+DQ+1bA0KZ5mA/peSTNPdATNSgzVwoChqeW3eNXN6+fbPHQon2a7duynmcfDn++cvbzms3PdFpo5vfw4t+ccolnnqy6kGQA0zqhPM9PEQ6fbMGLQxStHjoBhiqKD3y/MwV/Duuihafx5SL+ZV7o2LufbfPmKGmqkZ1K3Ica4+0ieb3z9M5o9/TY/554OM99+8JRv868f8c95q1aGc+7aQho9OeRDmpkKeWMN2ZZpvDoOAE1G3mFITRMPDdt1GSYTGrdpul+5ITPTlQERERGb02JARETE5rQYEBERsTktBkRERGxOiwERERGb02JARETE5mpdLQwP4+uGzRt/oFnhUV4tNA1M9FXwqW7FxSU0M01Ic4e7+P5Ki2gGAEcP82M9uHsPzRb8awHNjhTxfR4t5tWS6Bhe54uNT6BZZAyfrrV3L68PpiQ1oJk7hlcul8znjz1/y1qaVVbwqYVbc/jErr0l5tewuaHKFBvDJwXGxvNJbxEeXmaKjeTvN5ebV+o8HsMUtDooPZU/1nuH8s8Ovpl+Go7mNNiw0hgveY9XKwOLP6TZkyPb0uyL5av4/lb9l2adunSmWberetGsTVd+Dnjh+b/T7KbBI2mW0dXweUzhnzleOjx5Te8yT2VscddTNLuUv0zodlUkzZq34hMNu7blk3mRaZi+mMzr0zXRlQERERGb02JARETE5rQYEBERsTktBkRERGxOiwERERGb02JARETE5mpdLSzK4xXBRR/Np9menL00c/r4FMG1hqlVMNQH/X7TpDg+De6LTxbx+wEIc/G6V/sOHWlWERZNs8LyUppt382n8+XlbeD78/LHuD9nJ8127OTbvLDDBTS77x4+6WzZ0mya+Y/yiYaF5XzyVhl4xXP7CkNNDcCS7w7QLDKU1xldYbwaFxLO3xfRhmpheuMMmv3q2htpxl+JX67l82bxcB5/rHVG7nZjHJhnzpmcNH5eyd6zme8PfH/fZpuymbU7sJ9hzeezadYmlR/L6agP/i82mbLvefb697wGD6w/2cOhvvuaVzk7Xma+r64MiIiI2JwWAyIiIjanxYCIiIjNaTEgIiJic1oMiIiI2JwWAyIiIjZX62phWr00mjXPyKSZBV51C3XyLMRQH3SG8DWMFeDVszA3nyAFF58+BwD16/OpXT1696ZZtMcwDc8dT7P1P6yh2eat22iW2iCDZl6LP28hEfw4f9i8kWbrN/OKkyejFc327+ePPT6OZylhYXx/URE0A4D8nF00y9u3lWaHc/lEM2+lYfJmgL+HDxTwj17XK/j96qLf3HYDzd5+Y7jhnt5TfixnB68Izt72Hc06NeFbvDSzB81uHP7XWhzT2Xf9r+8724dwznl/ET+vqFooIiIiRloMiIiI2JwWAyIiIjanxYCIiIjNaTEgIiJic1oMiIiI2JwWAyIiIjbnsCyLF6V/4vWpM2jmc/B+t9PNx7iGh/PRsKGGvyXgdPIsYBn+dgH4/nwVlTQDgLIKPm7Y7+WjmB1ePho3PzefZh8smEOz9Tt5Jz6rDe80FxYfpdnhg7yDH/DzkcId2nSmWeOmbfk2Ld6HdTt55jGMki73FtEMAH5Y82+aRYC/vkcL+euUc6SYZjFJGTTz+fj79KKLL6bZjOkv0+yX6g/38Oc918XL9O6MRJqlN+Tvgzg+NRxuw58T8Rqmn0fxCLl8MjYAYOuB/TQ7soOP8Q3dycd8f/bpFzTbh1fMB1Qn8NceiDVkcYasviFbZTwaYF8N+S9fTf/U68qAiIiIzWkxICIiYnNaDIiIiNicFgMiIiI2p8WAiIiIzWkxICIiYnO1HmEc6eFVnrxCPmp01Vo+ojMlhY+qrZeSRDOfj9f1jhwpoBm8/DhDA3ybANAgk9dSGsbzLtO+zbx3VFLMK3sp9VJp5kmMo1mIO4ZmpWX88aelNaJZzv69NMvN43XFtPolNHMYai7F5YbXIpS/D30Bcz00PIKPsA43jMyuyDvMN+rk1dl6hnHSFeUVNKtd2bfuaNOaj//++L+7aTbtxW58o1E9aXTDzQNplpvL63oLP1/C91fMq7cx4NsEgPtG3UGz31/Fq8B/+fVbNNsHXlc8N5ieU/Pzza08yfvZg64MiIiI2JwWAyIiIjanxYCIiIjNaTEgIiJic1oMiIiI2JwWAyIiIjZX62phuItPWSv3FtDsv/9dSDPLx6tuMR4+CdHn4+PFvGV8gmCoYe3TOKMhzQCgzcWtada0Ea8dFuzhtbycI7k0C4vgFbqmibx2ePgwn6LXtkUbmp3XtgXNZk5/h2ahCKOZr4S/vhUVPLP8hoqgm7/2IeH8OQOAjEw+Ie/Qnk38jk4+7TIiku+zVassmnlL+evUMC2FH0sd1DCJv9Z7dxjqfOAT/VDMs1mvvV6Lozp1CmvIe93GK5L1O3egWZvJhumDuctq2OsZ1OEJnq167MwdxzmFn6uMnwv0Pek96sqAiIiIzWkxICIiYnNaDIiIiNicFgMiIiI2p8WAiIiIzWkxICIiYnO1rhaWlpXy0MnXFL37DqBZoIJPtQsx1AcDlbzmaIXwGlhIKK/BuSM9NAOAnAJeWSwq2Eyz/DL+OBxuN802reb1kbxsPkWvSSavCHZq1pxmFYaJhhFhvD5nGSZImqYkOkP4Wy/ABwiiLMBf+9BK/lwDQON0XtfxFvNJaK1j+LTDZd+totn+XbyuWFbC3/tW6RGa1UUbtvDPB9ymOmgvQ7bekBUYMj4pFOCvM1DPkPEKKQC8sYh/lpcv+p5mC7bwiaAAP3cA/HN38gyvxRY+0fHcMciQfXga9meqD5osOOk96sqAiIiIzWkxICIiYnNaDIiIiNicFgMiIiI2p8WAiIiIzWkxICIiYnO1rhZGRvFaXqzF7xedzGs35eW85uM2rFPCHPxYrAg+7TDcw+8X8PIpcgBQVMRnk4V4YmiW0jSOZk09fGrhlh3b+ME4eH3S5eFVrX0HdtMsMSn+pLKKMl6RKy/n1agSw0TDcsNEP185r7iGus310Hr1k2m268BBmh3czV8LbzF/jNvWraZZYiI/Fis+gWZ1UdsOvJbXzdAG7XTDizTbs2cfzTINtbvUUH4s/ua8eprein/mvDv20wwAVixfTrOoVp1odtOf+bTDrX/9mGa7ltxvPJ6T8wWPihNPw/5+aXiF+FyhKwMiIiI2p8WAiIiIzWkxICIiYnNaDIiIiNicFgMiIiI2p8WAiIiIzdV+amGRYfJYgK8pXI4omh08yGtZW9bvpJk7lNcHw2LjaJaUwity9ZNiaQYAoYbJjImxvFpjGLAIbxmfTpeSwuuKDerz6tmBnByabd68gWYZFZk0M1VAi4r4a1hayut6hUd5VdNULays4NMjQ8JNU+eAdT8k0ayivIJmKSm8jtagXRt+v2R+v6TkVJq5a3gcdc2G5Yaqm5dXYZNC29HsH29n02zW3pW1Oq7q+OvlSe1Js1GDuxi3GhfBq44Du/WhWbFh+OCuLYuN+zyz+MTPc8cvaTIjf5/WQ+uT3qquDIiIiNicFgMiIiI2p8WAiIiIzWkxICIiYnNaDIiIiNicFgMiIiI2V+tqYaCC91ychjVFqI9P+4px8d7dd0u/plnOQT7tz+HiVaXOnS+g2aVdLqQZABw9yit0a1d+S7MSL3/eNu/eQ7PtO3fSrKyUT+6zLAfN3DF8Ul5hYRHNio7w57ukkNcj+ZEAoSE8jY3m0wfrZ/IKZHximmGPQEp9Xuer36EtzRJieNUvLIS/v0MMmWnyJKxza43uPcBrWW7DhMG4w7yWfHEy/1x9tLd2x1Udr8KW5syk2Qdv8JojAGzz8sc/6fmRNR+W/MI1pknTOF71S43i55WoaP7eR6iheuznn6eanFtnHREREfnZtBgQERGxOS0GREREbE6LAREREZvTYkBERMTmtBgQERGxOYdlWdbZPggRERE5e3RlQERExOa0GBAREbE5LQZERERsTosBERERm9NiQERExOa0GBAREbE5LQZERERsTosBERERm9NiQERExOb+H76GAilvXS3CAAAAAElFTkSuQmCC","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["img, _ = transformed_cifar10_train_val[1]\n","img_t, _ = normalized_cifar10_train_val[1]\n","\n","# Clip the values between 0 and 1\n","img = np.clip(img, 0, 1)\n","img_t = np.clip(img_t, 0, 1)\n","\n","fig, ax = plt.subplots(1, 2)\n","\n","ax[0].imshow(img.permute(1, 2, 0))\n","ax[0].axis(\"off\")\n","ax[0].set_title(\"Transformed Image\")\n","\n","ax[1].imshow(img_t.permute(1, 2, 0))\n","ax[1].axis(\"off\")\n","ax[1].set_title(\"Normalized Image\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"CCl1SY6s2xNx"},"source":["As this is a binary classification problem where we only want to identify whether an image is a ship or not, we can set the labels that are \"ship\" to true. We set all other labels to false."]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"-GAC-KzK2xN1"},"source":["Splitting the training and validation set randomly."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13237,"status":"ok","timestamp":1682955460901,"user":{"displayName":"Østen Edvardsen","userId":"07919065933993283707"},"user_tz":-120},"id":"1O9NaXXd2xN2","outputId":"664efbb3-1f8f-44d6-e50f-b84c19034549"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of the train dataset:         45000\n","Size of the validation dataset:    5000\n","Size of the test dataset:          10000\n"]},{"data":{"text/plain":["Counter({8: 4486,\n","         7: 4486,\n","         1: 4512,\n","         6: 4510,\n","         3: 4516,\n","         5: 4487,\n","         4: 4499,\n","         2: 4483,\n","         0: 4518,\n","         9: 4503})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["n_train = len(transformed_cifar10_train_val)-n_val\n","\n","normalized_cifar10_train_split, normalized_cifar10_val_split = random_split(\n","    normalized_cifar10_train_val,\n","    [n_train, n_val],\n","\n","    generator=torch.Generator().manual_seed(seed)\n",")\n","\n","print(\"Size of the train dataset:        \", len(normalized_cifar10_train_split))\n","print(\"Size of the validation dataset:   \", len(normalized_cifar10_val_split))\n","print(\"Size of the test dataset:         \", len(normalized_cifar10_test))\n","\n","Counter([label for _, label in normalized_cifar10_train_split])"]},{"cell_type":"markdown","metadata":{"id":"PAxEPhDsnoA8"},"source":["Making this a binary clasification problem, where our designated category index is set to 1, and all other categories is set to 0. (The labels)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":14615,"status":"ok","timestamp":1682955475508,"user":{"displayName":"Østen Edvardsen","userId":"07919065933993283707"},"user_tz":-120},"id":"9cJ2L9x5tYgI"},"outputs":[],"source":["train10 = [(img, int(label == category_index)) for img, label in normalized_cifar10_train_split]\n","val10 = [(img, int(label == category_index)) for img, label in normalized_cifar10_val_split]\n","\n","train_loader = DataLoader(train10, batch_size=64, shuffle=False)\n","val_loader = DataLoader(val10, batch_size=64, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"nm4V0aKRp8To"},"source":["All of the models where found here: https://pytorch.org/vision/0.8/models.html\n","\n","Theese where the most used models, and we use all of them to see what models performes the best"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3500,"status":"ok","timestamp":1682955478997,"user":{"displayName":"Østen Edvardsen","userId":"07919065933993283707"},"user_tz":-120},"id":"McQZHj2Ur_MP","outputId":"33f5f6ed-9759-4483-aaf7-b8f7da430276"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\envs\\inf265\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  warnings.warn(\n","c:\\ProgramData\\Anaconda3\\envs\\inf265\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","c:\\ProgramData\\Anaconda3\\envs\\inf265\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","c:\\ProgramData\\Anaconda3\\envs\\inf265\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["import torchvision.models as models\n","\n","def modify_for_binary_classification(model):\n","    if isinstance(model, models.ResNet):\n","        model.fc = torch.nn.Linear(model.fc.in_features, 1)\n","    elif isinstance(model, models.AlexNet) or isinstance(model, models.vgg.VGG):\n","        model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, 1)\n","    elif isinstance(model, models.SqueezeNet):\n","        model.classifier[1] = torch.nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n","    elif isinstance(model, models.DenseNet):\n","        model.classifier = torch.nn.Linear(model.classifier.in_features, 1)\n","    elif isinstance(model, models.Inception3):\n","        model.AuxLogits.fc = torch.nn.Linear(model.AuxLogits.fc.in_features, 1)\n","        model.fc = torch.nn.Linear(model.fc.in_features, 1)\n","    elif isinstance(model, models.GoogLeNet):\n","        model.fc = torch.nn.Linear(model.fc.in_features, 1)\n","    elif isinstance(model, models.ShuffleNetV2):\n","        model.fc = torch.nn.Linear(model.fc.in_features, 1)\n","    elif isinstance(model, models.MobileNetV2):\n","        model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 1)\n","    else:\n","        raise NotImplementedError(\"Unknown model type\")\n","    return model\n","\n","model_list = [\n","    models.resnet18(weights='ResNet18_Weights.DEFAULT'),\n","    models.squeezenet1_0(weights='SqueezeNet1_0_Weights.DEFAULT'),\n","    models.googlenet(pretrained=True),\n","    models.shufflenet_v2_x1_0(pretrained=True),\n","    models.mobilenet_v2(pretrained=True),\n","]\n","\n","binary_model_list = [modify_for_binary_classification(model) for model in model_list]"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"hbU8atrq2xN9"},"source":["Loading pre-trained models and modifying the last layer. We are doing binary classification, so we think we only need one node in the final layer."]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"8tGhu8nO2xN-"},"source":["We use Binary Cross Entropy as it should be suitable for binary classification problems (add reasoning and explanation). We use nn.BCEWithLogitsLoss() as it combines the sigmoid activation function and the BCE into a single class.\n","\n","The optimizer we use is Adam, and we will begin with a learning rate of 0.001, just because it is a commonly used learning rate."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682955478999,"user":{"displayName":"Østen Edvardsen","userId":"07919065933993283707"},"user_tz":-120},"id":"R43qEeWB2xN_","outputId":"3594eaa1-b5ea-4ff8-8a95-8d5a531804f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training on device cpu.\n"]}],"source":["device = (torch.device('cuda') if torch.cuda.is_available()\n","          else torch.device('cpu'))\n","print(f\"Training on device {device}.\")"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1682955479001,"user":{"displayName":"Østen Edvardsen","userId":"07919065933993283707"},"user_tz":-120},"id":"ZvPz7_8G2xOA"},"outputs":[],"source":["def train(model, num_epochs, loader, optimizer, loss_function):\n","  try:\n","    model.to(device)\n","\n","    model.train()\n","    optimizer.zero_grad(set_to_none=True)\n","    for epoch in range(num_epochs):\n","      # Take a time stamp at the beginning of the epoch\n","      start_time = time.time()\n","\n","      running_loss = 0\n","\n","      for inputs, labels in loader:\n","        # Move the batch to the device we are using.\n","        inputs = inputs.to(device=device)\n","        labels = labels.to(device=device)\n","\n","        outputs = model(inputs).squeeze()\n","        loss = loss_function(outputs, labels.float())\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        running_loss += loss.item()\n","\n","      end_time = time.time()\n","      epoch_time = end_time - start_time\n","\n","      printModelInfo(model, epoch, epoch_time, (running_loss / len(loader)))\n","  except Exception as e:\n","    printModelInfo(model, e=e)\n","\n","def printModelInfo(model, epoch=None, epoch_time=None, lossData=None, e=None):\n","  if(e != None):\n","    e = str(e)[:20]\n","    print()\n","    print(\"-\"*50)\n","    print(f\"|{'Model: ' + type(model).__name__:^25}|{('Error: ' + str(e)):^22}|\")\n","    return\n","\n","  if(epoch == 0):\n","    modelTitle = \"Model name\"\n","    epochTitle = \"Epoch Nr\"\n","    timeTitle = \"Time (s)\"\n","    lossTitle = \"Loss (%)\"\n","    print()\n","    print(\"-\"*50)\n","    print(f'|{modelTitle:^15}|{epochTitle:^10}|{timeTitle:^10}|{lossTitle:^10}|')\n","    print(\"-\"*50)\n","\n","  modelName = (f'{type(model).__name__}')\n","  epochNr = (f'Nr.{epoch + 1}')\n","  time = (f'{epoch_time:.2f}s')\n","  lossD = (f'{100 * lossData:.2f}%')\n","\n","  print(f'|{modelName:^15}|{epochNr:^10}|{time:^10}|{lossD:^10}|')"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Fi0qr72Pt2hH"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","2\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m binary_model_list:\n\u001b[1;32m----> 2\u001b[0m   train(\n\u001b[0;32m      3\u001b[0m     model \u001b[39m=\u001b[39;49m model,\n\u001b[0;32m      4\u001b[0m     num_epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     loader \u001b[39m=\u001b[39;49m train_loader,\n\u001b[0;32m      6\u001b[0m     optimizer \u001b[39m=\u001b[39;49m optim\u001b[39m.\u001b[39;49mAdam(model\u001b[39m.\u001b[39;49mparameters(),  lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m),\n\u001b[0;32m      7\u001b[0m     loss_function \u001b[39m=\u001b[39;49m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mBCEWithLogitsLoss()\n\u001b[0;32m      8\u001b[0m   )\n\u001b[0;32m      9\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m50\u001b[39m)\n","Cell \u001b[1;32mIn[12], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, num_epochs, loader, optimizer, loss_function)\u001b[0m\n\u001b[0;32m     21\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     22\u001b[0m loss \u001b[39m=\u001b[39m loss_function(outputs, labels\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m---> 23\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     24\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     25\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\inf265\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\inf265\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for model in binary_model_list:\n","  train(\n","    model = model,\n","    num_epochs = 10,\n","    loader = train_loader,\n","    optimizer = optim.Adam(model.parameters(),  lr=0.001),\n","    loss_function = torch.nn.BCEWithLogitsLoss()\n","  )\n","  print(\"-\"*50)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"1PvqVbWuch4m"},"outputs":[],"source":["def compute_accuracy_on_gpu(model, loader):\n","  try:\n","    # set the model to evaluation mode\n","    model.eval()\n","\n","    # Initialize counters for number of correctly and total labeled samples\n","    correct = 0\n","    total = 0\n","\n","    # Turn off gradient computation since we are not training   \n","    with torch.no_grad():\n","        # Iterate over the data loader\n","        for img, labels in loader:\n","            # Move the input and target tensors to the specified device\n","            img = img.to(device=device, dtype=torch.double)\n","            labels = labels.to(device=device)\n","            \n","            # Forward pass through the model to get the outputs\n","            outputs = model(img)\n","\n","            # Apply sigmoid activation function\n","            sigmoid = torch.sigmoid(outputs).squeeze()\n","\n","            # Threshold the outputs to get the predicted class\n","            predicted = (sigmoid > 0.5).long()\n","\n","            # Update the counters for correctly and total labeled samples\n","            total += labels.shape[0]\n","            correct += int((predicted == labels).sum())\n","\n","    # Compute and return the accuracy  \n","    return correct/total\n","  except Exception as e:\n","    return e\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def printAccInfo(model):\n","    modelName = \"Model: \" + type(model).__name__\n","    trainingAccuracy = compute_accuracy_on_gpu(model, train_loader)\n","\n","    if isinstance(trainingAccuracy, Exception):\n","        print(f\"Error on model {type(model).__name__}\" )\n","        return\n","  \n","    ValidationAccuracy = compute_accuracy_on_gpu(model, val_loader)\n","\n","    trainString = (f\"Training Accuracy: {100 * trainingAccuracy:.2f}%\")\n","    valString = (f\"Validation Accuracy: {100 * ValidationAccuracy:.2f}%\")\n","\n","    print(f'|{modelName:^25}|{trainString:^30}|{valString:^30}|')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for model in binary_model_list:\n","    printAccInfo(model)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["import torch.nn.functional as F\n","class MyNetBis(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(32*32*3, 256)\n","        self.fc2 = nn.Linear(256, 64)\n","        self.fc3 = nn.Linear(64, 1)  # Change the output size to 1\n","        \n","    def forward(self, x):\n","        out = torch.flatten(x, 1)\n","        out = torch.tanh(self.fc1(out))\n","        out = F.relu(self.fc2(out))\n","        out = self.fc3(out)\n","        return out\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--------------------------------------------------\n","|  Model name   | Epoch Nr | Time (s) | Loss (%) |\n","--------------------------------------------------\n","|   MyNetBis    |   Nr.1   |  76.71s  |  69.38%  |\n","|   MyNetBis    |   Nr.2   |  76.55s  |  69.38%  |\n","|   MyNetBis    |   Nr.3   |  77.29s  |  69.38%  |\n","--------------------------------------------------\n"]}],"source":["myModel = MyNetBis().to(device=device)\n","# WARNING. This is supposed to much much faster than previously but it \n","# might still take a while if your gpu is not available\n","# AGAIN STOP YOUR KERNEL IF IT'S TOO SLOW \n","train(\n","    model = myModel,\n","    num_epochs = 3,\n","    loader = train_loader,\n","    optimizer = optim.Adam(model.parameters(),  lr=1e-5),\n","    loss_function = torch.nn.BCEWithLogitsLoss()\n",")\n","print(\"-\"*50)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["|     Model: MyNetBis     |  Training Accuracy: 50.56%   | Validation Accuracy: 50.58%  |\n"]}],"source":["printAccInfo(myModel)"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
